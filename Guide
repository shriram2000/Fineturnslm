# Fashion Product Recommendation System - Quick Start Guide

## üéØ Project Overview

Build a personalized product recommendation system using a Small Language Model (SLM) trained on fashion retail transaction data from Kaggle.

**Dataset**: [Global Fashion Retail Stores Dataset](https://www.kaggle.com/datasets/ricgomes/global-fashion-retail-stores-dataset)

---

## üì¶ Installation

### Prerequisites
```bash
# Python 3.8+
python --version

# Install required packages
pip install pandas numpy torch transformers datasets peft accelerate bitsandbytes
pip install scikit-learn tqdm
```

### Download Dataset
```bash
# Option 1: Using Kaggle API
pip install kaggle
kaggle datasets download -d ricgomes/global-fashion-retail-stores-dataset
unzip global-fashion-retail-stores-dataset.zip

# Option 2: Manual download from Kaggle website
# Place CSV files in a 'data/' directory
```

---

## üöÄ Step-by-Step Implementation

### **Step 1: Data Preparation**

Run the data preparation pipeline:

```python
from fashion_data_prep import FashionRecommendationDataPrep

# Initialize pipeline
pipeline = FashionRecommendationDataPrep()

# Load CSV files
pipeline.load_data('data/')  # Path to your CSV files

# Clean and prepare data
pipeline.clean_and_prepare_data()

# Create customer profiles
profiles = pipeline.create_customer_profiles()

# Generate training samples (5000 examples)
training_data = pipeline.generate_training_prompts(profiles, num_samples=5000)

# Export training data
pipeline.export_training_data(training_data, 'fashion_recommendations_train.jsonl')

# Create product catalog
catalog = pipeline.create_product_catalog_embeddings()

# View statistics
pipeline.generate_summary_statistics(profiles, training_data)
```

**Output**: `fashion_recommendations_train.jsonl` (ready for SLM training)

---

### **Step 2: Train the SLM**

```python
from train_slm import FashionRecommenderSLM

# Initialize training
slm = FashionRecommenderSLM(
    model_name="microsoft/phi-2",  # 2.7B parameters
    use_lora=True  # Efficient fine-tuning
)

# Load training data
dataset = slm.load_training_data('fashion_recommendations_train.jsonl')

# Prepare model and tokenizer
slm.prepare_model_and_tokenizer()

# Train (takes 2-4 hours on GPU)
slm.train(
    dataset=dataset,
    output_dir="fashion_recommender_model",
    num_epochs=3,
    batch_size=4,
    learning_rate=2e-4
)
```

**Training Resources**:
- **GPU**: NVIDIA T4 or better (recommended)
- **RAM**: 16GB+ system memory
- **VRAM**: 8GB+ GPU memory
- **Time**: 2-4 hours with GPU, 12-24 hours with CPU

---

### **Step 3: Generate Recommendations**

```python
# Load trained model
slm = FashionRecommenderSLM(model_name="fashion_recommender_model")
slm.prepare_model_and_tokenizer()

# Example customer profile
customer_profile = """Customer Profile:
- Gender: F
- Age: 28 years (26-35)
- Location: Los Angeles, United States
- Total Orders: 12
- Total Spending: $1,850.00
- Favorite Category: Feminine
- Preferred Subcategories: Dresses, T-shirts and Tops
- Favorite Colors: Black, White, Pink
- Preferred Sizes: S, M

Recent Purchase History:
- Feminine > Dresses: summer floral dress (Pink, Size: S) - $65.00
- Feminine > T-shirts and Tops: casual cotton tee (White, Size: M) - $25.00

Based on this customer's profile and shopping history, suggest 5 personalized product recommendations:"""

# Generate recommendations
recommendations = slm.generate_recommendations(customer_profile)
print(recommendations)
```

---

## üìä Expected Output Example

```
Recommended Products:

1. Feminine - Skirts
   Description: elegant midi pencil skirt
   Color: Black, Available Sizes: S | M | L
   Price: $54.99
   Why: Matches your preference for Feminine items in Black

2. Feminine - Dresses
   Description: casual summer sundress
   Color: White, Available Sizes: S | M | L | XL
   Price: $48.99
   Why: Matches your preference for Feminine items in White

3. Feminine - T-shirts and Tops
   Description: stylish crop top with prints
   Color: Pink, Available Sizes: S | M
   Price: $32.99
   Why: Matches your preference for Feminine items in Pink

4. Feminine - Coats and Blazers
   Description: professional blazer jacket
   Color: Black, Available Sizes: S | M | L
   Price: $89.99
   Why: Complements your wardrobe with versatile Black pieces

5. Feminine - Dresses
   Description: evening cocktail dress
   Color: Black, Available Sizes: S | M
   Price: $95.00
   Why: Matches your preference for Feminine items in Black
```

---

## üéõÔ∏è Model Configuration Options

### Recommended Models

| Model | Parameters | Speed | Quality | Use Case |
|-------|-----------|-------|---------|----------|
| **microsoft/phi-2** | 2.7B | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | Best balance |
| **TinyLlama-1.1B** | 1.1B | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Fast inference |
| **Llama-2-7b-chat** | 7B | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | Highest quality |

### LoRA Configuration (Memory-Efficient Fine-tuning)

```python
lora_config = LoraConfig(
    r=16,              # Rank: 8-64 (higher = more capacity)
    lora_alpha=32,     # Scaling factor
    lora_dropout=0.05, # Dropout for regularization
    target_modules=["q_proj", "v_proj"]  # Which layers to fine-tune
)
```

---

## üìà Evaluation Metrics

### Recommendation Quality
- **Hit Rate @5**: Did any of the 5 recommendations match actual purchases?
- **NDCG @5**: Normalized Discounted Cumulative Gain
- **Category Accuracy**: % of recommendations in correct category

### Business Metrics
- **Click-Through Rate**: % of recommendations clicked
- **Conversion Rate**: % of recommendations purchased
- **Revenue per Recommendation**: Average $ from recommendations

---

## üîß Troubleshooting

### Common Issues

**1. Out of Memory (OOM) Error**
```python
# Solution: Reduce batch size
batch_size=2  # Instead of 4

# Or enable gradient accumulation
gradient_accumulation_steps=8
```

**2. Slow Training**
```python
# Use smaller model
model_name="TinyLlama/TinyLlama-1.1B-Chat-v1.0"

# Reduce max sequence length
max_length=512  # Instead of 1024
```

**3. Poor Recommendations**
```python
# Train for more epochs
num_epochs=5  # Instead of 3

# Use more training data
num_samples=10000  # Instead of 5000

# Adjust generation parameters
temperature=0.7  # Lower = more focused (0.6-0.8)
top_p=0.9       # Nucleus sampling (0.8-0.95)
```

---

## üöÄ Deployment Options

### Option 1: REST API (Flask)
```python
from flask import Flask, request, jsonify

app = Flask(__name__)
slm = FashionRecommenderSLM(model_name="fashion_recommender_model")
slm.prepare_model_and_tokenizer()

@app.route('/recommend', methods=['POST'])
def recommend():
    customer_profile = request.json['profile']
    recommendations = slm.generate_recommendations(customer_profile)
    return jsonify({'recommendations': recommendations})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### Option 2: FastAPI (Production)
```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()
slm = FashionRecommenderSLM(model_name="fashion_recommender_model")

class CustomerProfile(BaseModel):
    profile: str

@app.post("/recommend")
async def recommend(customer: CustomerProfile):
    recommendations = slm.generate_recommendations(customer.profile)
    return {"recommendations": recommendations}
```

### Option 3: Cloud Deployment
- **AWS SageMaker**: Managed ML deployment
- **Google Cloud Run**: Containerized serverless
- **Azure ML**: Enterprise ML platform
- **Hugging Face Spaces**: Free hosting for demos

---

## üìö Advanced Features

### 1. **Multi-lingual Support**
```python
# The dataset has descriptions in multiple languages
# Train separate models or use multilingual base models
model_name="xlm-roberta-base"  # Multilingual
```

### 2. **Real-time Personalization**
```python
# Update customer profile with new purchases
def update_profile(customer_id, new_purchase):
    # Add to purchase history
    # Regenerate recommendations
    pass
```

### 3. **A/B Testing**
```python
# Compare SLM vs traditional recommendations
# Track metrics: CTR, conversion, revenue
```

### 4. **Cold Start Problem**
```python
# For new customers without history
# Use demographic-based recommendations
# Popular items in their location/age group
```

---

## üìä Performance Benchmarks

**On NVIDIA T4 GPU:**
- Training: ~3 hours for 5000 samples (3 epochs)
- Inference: ~200-300ms per recommendation
- Model size: ~5.4GB (Phi-2 with LoRA)

**On CPU:**
- Training: ~24 hours for 5000 samples
- Inference: ~2-3 seconds per recommendation

---

## ü§ù Contributing & Next Steps

### Improvements to Consider
1. **Add customer feedback loop** - Learn from clicks/purchases
2. **Implement diversity** - Don't recommend similar items only
3. **Add explanations** - Why this product is recommended
4. **Seasonal trends** - Consider time-of-year patterns
5. **Bundle recommendations** - Complete outfit suggestions
6. **Price sensitivity** - Match customer's budget preferences

---

## üìû Support

- **Issues**: Check error messages carefully
- **Documentation**: Hugging Face Transformers docs
- **Community**: r/MachineLearning, Hugging Face forums

---

## ‚úÖ Checklist

- [ ] Dataset downloaded and extracted
- [ ] Environment set up with all dependencies
- [ ] Data preparation pipeline executed
- [ ] Training data generated (JSONL file)
- [ ] Model training completed
- [ ] Inference tested with sample customers
- [ ] Evaluation metrics calculated
- [ ] Model saved and ready for deployment

**üéâ Congratulations! Your fashion recommendation system is ready!**
